## 单阶段与多阶段的区别
[知乎参考](https://zhuanlan.zhihu.com/p/367069340)
当前人脸检测方法继承了一些通用检测方法的成果，主要分为两类：两阶方法如Faster RCNN和单阶方法如SSD和RetinaNet。两阶方法应用一个“proposal and refinement”机制提取高精度定位。而单阶方法密集采样人脸位置和尺度，导致训练过程中极度不平衡的正样本和负样本。为了处理这种不平衡，采样和re-weighting方法被广泛使用。相比两阶方法，单阶方法更高效并且有更高的召回率，但是有获取更高误报率的风险，影响定位精度。
多阶方法一个重要的模块为ROI pooling层

## Spatial Pyramid Pooling（SPP）
首先在SPPNet中提出，将RCNN中的resize输入图像到固定尺寸修改为使用SPP模块将特征resize到固定维度，并且pooling的kernel取了多个不同维度，意味着不同空间分辨率的特征。该模块计算量较大
![sppnet](pics/sppnet.jpg)
SPPNet只需要计算一次CNN就可以得到整张图的feature map,再通过box坐标映射得到ROI区域的特征图。和RCNN一样，SPP也需要训练CNN提取特征，然后训练SVM分类这些特征。需要巨大的存储空间，并且分开训练也很复杂。而且selective search的方法提取特征是在CPU上进行的，相对于GPU来说还是比较慢的。

## ROI pooling 与 fast RCNN
[知乎参考](https://zhuanlan.zhihu.com/p/165324194)
ROI pooling是多阶目标检测任务中常用的层，首先在fast rcnn（首次对box进行回归）中使用,作用是将第一阶段得到的region proposals的box对应到feature map上的区域特征，进行pooling，得到固定维度的输出，才能送入全连接层。ROI pooling计算过程中会涉及两次浮点到整型的“四舍五入”操作，后面网络基于此将两次近似操作合并为一次，降低误差  
### 如果对应到feature map上的ROI区域较小，尺寸小于pooling的输出尺寸，如何处理？
[知乎参考](https://www.zhihu.com/question/353305355)


## Region Proposal Networks(RPN) 和 Faster RCNN
RPN首次在Faster RCNN中提出，用于取代selective search（天下苦秦久矣），使得全部模型能够使用深度学习模型

## Feature Pyramid Network(FPN)
在faster rcnn的基础上，提出特征金字塔融合模型，使得低层级特征图能够感知到高层级特征，具体结构如下：
![FPN](pics/fpn.jpg)

## 第一个单阶段检测网络YOLO
速度快，精度低于二阶段

## SSD
与YOLO V1不同的是，利用在多个层级的feature map都做预测

## YOLOV2
[参考知乎](https://zhuanlan.zhihu.com/p/74540100)
在v2中，神经网络不对预测矩形框的宽高的绝对值进行预测，而是预测与Anchor框的偏差（offset）。  
对于box的位置，直接预测绝对的像素个数，不与anchor的宽高成比例。  
Dimension Clusters（Anchor Box的宽高由聚类产生）。  
【不足】 YOLO v2算法只有一条检测分支，且该网络缺乏对多尺度上下文信息的捕获，所以对于不同尺寸的目标检测效果依然较差，尤其是对于小目标检测问题。

## RetinaNet与Focal loss
Focal Loss使得模型的训练更专注于困难样本.
[参考博客](https://www.cnblogs.com/king-lps/p/9497836.html)
[二分类与多分类focal loss](https://www.cnblogs.com/CheeseZH/p/13519206.html)

## Anchor-based目标检测算法局限性
1. Anchor的大小，数量，长宽比对于检测性能的影响很大(通过改变这些超参数Retinanet在COCO benchmark上面提升了4%的AP)，因此Anchor based的检测性能对于anchor的大小、数量和长宽比都非常敏感。
2. 这些固定的Anchor极大地损害了检测器的普适性，导致对于不同任务，其Anchor都必须重新设置大小和长宽比。
3. 为了去匹配真实框，需要生成大量的Anchor，但是大部分的Anchor在训练时标记为负样本，所以就造成了样本极度不均衡问题(没有充分利用fore-ground)。
4. 在训练中，网络需要计算所有Anchor与真实框的IOU，这样就会消耗大量内存和时间。


## Anchor-Free 


## IOU loss
[参考知乎](https://zhuanlan.zhihu.com/p/44323675)
IOU loss的计算方式：
![IOU-LOSS](pics/IOU-loss.jpg)

## GIOU loss
[参考知乎：目标检测算法之CVPR2019 GIoU Loss](https://zhuanlan.zhihu.com/p/97340657)
IOU loss的缺点：
1）预测框bbox和ground truth bbox如果没有重叠，IOU就始终为0并且无法优化。也就是说损失函数失去了可导的性质。
2）IOU无法分辨不同方式的对齐，例如方向不一致等，如下图所示，可以看到三种方式拥有相同的IOU值，但空间却完全不同。

GIOU计算方式：
![GIOU计算方式](pics/GIOU-LOSS.jpg)

## Decoupled Head
经典的检测算法，分类和box坐标回归使用相同的特征图，但是后续方法证实，不同使用不同分支提取不同的特征会提升精度，该操作称作Decoupled Head
![Decoupled-Head](pics/Decoupled-Head.jpg)

## SimOTA
[知乎详解](https://zhuanlan.zhihu.com/p/394392992)
用于anchor-free检测方法中的正样本选取
优点：
1、simOTA能够做到自动的分析每个gt要拥有多少个正样本。
2、能自动决定每个gt要从哪个特征图来检测。
3、相比较OTA，simOTA运算速度更快。
4、相比较OTA，避免额外超参数。




