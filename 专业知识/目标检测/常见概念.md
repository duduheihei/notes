## 单阶段与多阶段的区别
[知乎参考](https://zhuanlan.zhihu.com/p/367069340)
当前人脸检测方法继承了一些通用检测方法的成果，主要分为两类：两阶方法如Faster RCNN和单阶方法如SSD和RetinaNet。两阶方法应用一个“proposal and refinement”机制提取高精度定位。而单阶方法密集采样人脸位置和尺度，导致训练过程中极度不平衡的正样本和负样本。为了处理这种不平衡，采样和re-weighting方法被广泛使用。相比两阶方法，单阶方法更高效并且有更高的召回率，但是有获取更高误报率的风险，影响定位精度。
多阶方法一个重要的模块为ROI pooling层

## Spatial Pyramid Pooling（SPP）
首先在SPPNet中提出，将RCNN中的resize输入图像到固定尺寸修改为使用SPP模块将特征resize到固定维度，并且pooling的kernel取了多个不同维度，意味着不同空间分辨率的特征。该模块计算量较大
![sppnet](pics/sppnet.jpg)
SPPNet只需要计算一次CNN就可以得到整张图的feature map,再通过box坐标映射得到ROI区域的特征图。和RCNN一样，SPP也需要训练CNN提取特征，然后训练SVM分类这些特征。需要巨大的存储空间，并且分开训练也很复杂。而且selective search的方法提取特征是在CPU上进行的，相对于GPU来说还是比较慢的。
在后续YOLO系列中也出现

## ROI pooling 与 fast RCNN
[知乎参考](https://zhuanlan.zhihu.com/p/165324194)
ROI pooling是多阶目标检测任务中常用的层，首先在fast rcnn（首次对box进行回归）中使用,作用是将第一阶段得到的region proposals的box对应到feature map上的区域特征，进行pooling，得到固定维度的输出，才能送入全连接层。ROI pooling计算过程中会涉及两次浮点到整型的“四舍五入”操作，后面网络基于此将两次近似操作合并为一次，降低误差  
### 如果对应到feature map上的ROI区域较小，尺寸小于pooling的输出尺寸，如何处理？
[知乎参考](https://www.zhihu.com/question/353305355)


## Region Proposal Networks(RPN) 和 Faster RCNN
RPN首次在Faster RCNN中提出，用于取代selective search（天下苦秦久矣），使得全部模型能够使用深度学习模型

## Feature Pyramid Network(FPN)
在faster rcnn的基础上，提出特征金字塔融合模型，使得低层级特征图能够感知到高层级特征，具体结构如下：
![FPN](pics/fpn.jpg)


## 第一个单阶段检测网络YOLO
[知乎科技猛兽：你一定从未看过如此通俗易懂的YOLO系列](https://zhuanlan.zhihu.com/p/183261974)
速度快，精度低于二阶段,相同anchor中，不同box公用一个分类器，因此会造成冲突。只使用一个feature map做预测
YOLOv1在特征图(7X7)的每一个网格里预测出2个bounding box

## SSD
与YOLO V1不同的是，利用在多个层级的feature map都做预测


## YOLOV2
[参考知乎](https://zhuanlan.zhihu.com/p/74540100)
在v2中，神经网络不对预测矩形框的宽高的绝对值进行预测，而是预测与Anchor框的偏差（offset）。  
对于box的位置，直接预测绝对的像素个数，不与anchor的宽高成比例。  
Dimension Clusters（Anchor Box的宽高由聚类产生）。  
【不足】 YOLO v2算法只有一条检测分支，且该网络缺乏对多尺度上下文信息的捕获，所以对于不同尺寸的目标检测效果依然较差，尤其是对于小目标检测问题。
YOLOv2在特征图(13X13)的每一个网格里预测5个bounding box，每个bounding box预测出5个值以及分类概率值

## YOLOV3
[参考博客](https://blog.csdn.net/weixin_51296032/article/details/123009246)
特征图进行了融合，融合后使用三个level的特征图。
YOLOV3在3个特征图的每一个网格中预测出3个bounding box，每个bounding box预测5个值以及分类概率值
YOLOv3使用Logistic regression来预测每个bounding box的confidence,以bounding box与gt的IOU为判定标准,对每个gt只分配一个最好的bounding box.通过利用这种方式,在做Detect之前可以减少不必要的Anchor进而减少计算量.

## YOLOV4
[参考博客:yolov4的全面详解](https://blog.csdn.net/hgnuxc_1993/article/details/120724812)
数据增强：图像几何变换（随机缩放，裁剪，旋转），Cutmix，Mosaic等
损失函数的设计：边界框回归的损失函数的改进 CIOU
增大模型感受野：SPP、ASPP等
引入注意力机制：SE、SAM
特征集成：PAN，BiFPN
激活函数改进：Swish、Mish
后处理方法改进：soft NMS、DIoU NMS

## RetinaNet与Focal loss
Focal Loss使得模型的训练更专注于困难样本.
[参考博客](https://www.cnblogs.com/king-lps/p/9497836.html)
[二分类与多分类focal loss](https://www.cnblogs.com/CheeseZH/p/13519206.html)

## Anchor-based目标检测算法局限性
1. Anchor的大小，数量，长宽比对于检测性能的影响很大(通过改变这些超参数Retinanet在COCO benchmark上面提升了4%的AP)，因此Anchor based的检测性能对于anchor的大小、数量和长宽比都非常敏感。
2. 这些固定的Anchor极大地损害了检测器的普适性，导致对于不同任务，其Anchor都必须重新设置大小和长宽比。
3. 为了去匹配真实框，需要生成大量的Anchor，但是大部分的Anchor在训练时标记为负样本，所以就造成了样本极度不均衡问题(没有充分利用fore-ground)。
4. 在训练中，网络需要计算所有Anchor与真实框的IOU，这样就会消耗大量内存和时间。


## Anchor-Free 
yolov3,yolox直接回归左上点和右下点距离feature pixel的距离


## IOU loss
[参考知乎](https://zhuanlan.zhihu.com/p/44323675)
IOU loss的计算方式：
![IOU-LOSS](pics/IOU-loss.jpg)

## GIOU loss
[参考知乎：目标检测算法之CVPR2019 GIoU Loss](https://zhuanlan.zhihu.com/p/97340657)
IOU loss的缺点：
1）预测框bbox和ground truth bbox如果没有重叠，IOU就始终为0并且无法优化。也就是说损失函数失去了可导的性质。
2）IOU无法分辨不同方式的对齐，例如方向不一致等，如下图所示，可以看到三种方式拥有相同的IOU值，但空间却完全不同。

GIOU计算方式：
![GIOU计算方式](pics/GIOU-LOSS.jpg)

## IOU GIOU DIOU CIOU
[参考博客](https://blog.csdn.net/bu_fo/article/details/110428980)

## Decoupled Head
经典的检测算法，分类和box坐标回归使用相同的特征图，但是后续方法证实，不同使用不同分支提取不同的特征会提升精度，该操作称作Decoupled Head
![Decoupled-Head](pics/Decoupled-Head.jpg)

## OTA， Optimal Transport Algorithm
将Label Assign当作二分图匹配来做，可以依据网络的训练，动态的选取样本。

## SimOTA
[知乎详解](https://zhuanlan.zhihu.com/p/394392992)
用于anchor-free检测方法中的正样本选取
优点：
1、simOTA能够做到自动的分析每个gt要拥有多少个正样本。
2、能自动决定每个gt要从哪个特征图来检测。
3、相比较OTA，simOTA运算速度更快。
4、相比较OTA，避免额外超参数。。

## 目标检测网络中的 bottom-up 和 top-down理解
[参考博客](https://blog.csdn.net/qq_44442727/article/details/114692401)

## CSP_DarkNet网络解析
### Focus层
[参考](https://zhuanlan.zhihu.com/p/513312921)
位于网络的第一层，将输入图像等间隔抽样成四个子图像，再concat为3*4 channel的图像送到卷积层，可以提升训练速度，但使用到slice操作，硬件未必友好，量化也未必友好

### SPP_Block
全称[Spatial Pyramid Pooling](https://zhuanlan.zhihu.com/p/396724233)，使用不同kernel size的maxpooling层，提取不同感受野的特征，得到更加丰富的特征。插入到网络的layer中，可以提点

### CSP_Layer
全称[Cross Stage Partial Layer](https://blog.csdn.net/cdknight_happy/article/details/107962173?spm=1001.2014.3001.5502)
里面的梯度复用问题有点难理解，听起来就是越往前的节点，会利用到后面多个节点的梯度信息，“这将导致无差异的稠密层反复学习同样的梯度信息”（这句话很难理解），
[mmdetection](https://github.com/open-mmlab/mmdetection/blob/56e42e72cdf516bebb676e586f408b98f854d84c/mmdet/models/utils/csp_layer.py#L75)中，该层的具体实现不太一样，但是会将输入通道压缩为1/2，走两路分支，concate后再卷积一次,这样主干分支计算量就相对减少了  
![CSP_Layer](pics/CSP_Layer.png)




